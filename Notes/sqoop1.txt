sqoop list-databases --connect jdbc:mysql://client.cluster1.com/employee --username sqoop --password passwd

sqoop list-tables --connect jdbc:mysql://client.cluster1.com/employee --username sqoop --password passwd


sqoop import --connect jdbc:mysql://client.cluster1.com/employee --username sqoop --password passwd --table student -m 1 --target-dir /user/sqoop/employee

sqoop import --connect jdbc:mysql://client.cluster1.com/employee --username sqoop --password passwd --table student -m 1 --target-dir /user/sqoop/employee


sqoop --options-file SqoopImportOptions.txt \
--table employees  \
--where "emp_no > 499948" \
--as-textfile \
-m 1 \
--target-dir /user/airawat/sqoop-mysql/employeeGtTest


sqoop --options-file SqoopImportOptions.txt \
--query 'select EMP_NO,FIRST_NAME,LAST_NAME from employees where $CONDITIONS' \
--fetch-size=50000 \
--split-by EMP_NO \
--direct \
--target-dir /user/airawat/sqoop-mysql/FetchSize

sqoop --options-file SqoopImportOptions.txt \

--query 'select EMP_NO,FIRST_NAME,LAST_NAME from employees where $CONDITIONS' \
-z \
--split-by EMP_NO \
--direct \
--target-dir /user/airawat/sqoop-mysql/CompressedSampl

=================
mysql> create table employee(id varchar(20),name varchar(20),salary varchar(10));

hive -> CREATE External TABLE emp_hive (id INT, name STRING, salary STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE location '/user/hadoop/table';


sqoop import --connect jdbc:mysql://repo.cluster1.com/test --username hadoop --password hivepassword --table employee --target-dir /user/hadoop/table -m 1 --incremental append -check-column id

#!/bin/bash

for i in `seq 1 100`
do
	echo "insert into test.employee(id,name,salary) values('${i}','Am${i}','10000');"
done
